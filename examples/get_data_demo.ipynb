{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b0dd121",
   "metadata": {},
   "source": [
    "# `get_data()` Demo Notebook from `CIROH-UVM/forecast-workflow`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b941ce6",
   "metadata": {},
   "source": [
    "## Setup\n",
    "1. Clone the [forecast-workflow repository](https://github.com/CIROH-UVM/forecast-workflow/tree/main) to your user space on the testbed\n",
    "2. Launch Jupyter Lab and select the kernel called \"forecast\"\n",
    "3. Add the path to your cloned repo to you Python path by running the cell below (only run once per notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f75820-a8a1-4a3a-9929-2f70757a905c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import sys\n",
    "# sys.path.append('/your/path/to/forecast-workflow')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cc2623",
   "metadata": {},
   "source": [
    "## NWM forecasted streamflow data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3c2125",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A function to download and process NWM hydrology forecast data to return nested dictionary of pandas series fore each variable, for each location.\n",
    "\n",
    "Args:\n",
    "-- forecast_datetime (str, date, or datetime) [req]: the start date and time (00, 06, 12, 18) of the forecast to download. Times are assumed to be UTC time.\n",
    "-- end_datetime (str, date, or datetime) [req]: the end date and time for the forecast. GFS forecasts 16-days out for a given start date.\n",
    "-- locations (dict) [req]: a dictionary (stationID/name:IDValue/latlong tuple) of locations to download forecast data for.\n",
    "-- forecast_type (str) [req]: The type of forecast.\n",
    "-- data_dir (str) [opt]: directory to store donwloaded data. Defaults to OS's default temp directory.\n",
    "-- dwnld_threads (int) [opt]: number of threads to use for downloads. Default is half of OS's available threads.\n",
    "-- load_threads (int) [opt]: number of threads to use for reading data. Default is 2 for GFS, since file reads are already pretty fast.\n",
    "-- forecast_cycle (str) [req]: The starting time for the forecasts. valid values are 00, 06, 12, 18\n",
    "-- google_buckets (bool) [opt]: Flag determining wether or not to use google buckets for nwm download as opposed to NOMADs site.\n",
    "-- archive (bool) [opt]: Flag determining wether or not data you are grabbing is older than the last two days (relevant for NWM only)\n",
    "-- return_type (string) [opt]: string indicating which format to return data in. Default is \"dict\", which will return data in a nested dict format:\n",
    "\t\t\t\t\t\t\t\t{locationID1:{\n",
    "\t\t\t\t\t\t\t\t\tvar1_name:pd.Series,\n",
    "\t\t\t\t\t\t\t\t\tvar2_name:pd.Series,\n",
    "\t\t\t\t\t\t\t\t\t...},\n",
    "\t\t\t\t\t\t\t\tlocationID2:{...},\n",
    "\t\t\t\t\t\t\t\t...\n",
    "\t\t\t\t\t\t\t\t}\n",
    "\t\t\t\t\t\t\t\tAlternative return type is \"dataframe\", which smashes all data into a single dataframe muliIndex'd by station ID, then timestamp\t\n",
    "Returns:\n",
    "NWM data in the format specified by return_type\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c1d4d0-8595-4cde-bb53-9550ef55133a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import data.nwm_fc as nwm\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "\n",
    "fc_start_dt = dt.datetime(2024, 1, 16, 6)\n",
    "# without an hour specified, will default to midnight forecast cycle\n",
    "# fc_start_dt = \"202401016\"\n",
    "\n",
    "# use the same hour as our start datetime, so that we get a full 10 days of fc data\n",
    "fc_end_dt = dt.datetime(2024, 1, 26, 6)\n",
    "\n",
    "# define some locations to grab data for. Reach IDs for the NWM can be found at: \n",
    "# https://water.noaa.gov/map\n",
    "reaches =  {\"Missisquoi River\":\"166176984\",\n",
    "\t\t\t\"Jewett Brook\":\"4587092\",\n",
    "            \"Mill River\":\"4587100\"}\n",
    "\n",
    "fc_type = \"medium_range_mem1\"\n",
    "\n",
    "# define a directory in which to download NWM data\n",
    "data_directory = \"/data/users/n/b/nbeckage/forecastData/\"\n",
    "\n",
    "# yes, we want to use google buckets for all data older than yesterday\n",
    "buckets = True\n",
    "arch = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296fab2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nwm_data = nwm.get_data(forecast_datetime = fc_start_dt,\n",
    "\t\t\t \t\t   end_datetime = fc_end_dt,\n",
    "\t\t\t \t\t   locations = reaches,\n",
    "\t\t\t\t\t   forecast_type = fc_type,\n",
    "\t\t\t\t\t   data_dir = data_directory,\n",
    "\t\t\t\t\t   google_buckets = buckets,\n",
    "\t\t\t\t\t   archive = arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4382e2ef-8165-4062-9614-bd5e5d923d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "nwm_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1ded11",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(nwm_data['Missisquoi River']['streamflow'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c484b8-f7e2-4502-85f5-4e367938acaf",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## USGS observed streamflow data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74210347",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A function to download and process USGS observational hydrology data to return nested dictionary of pandas series fore each variable, for each location.\n",
    "\n",
    "Args:\n",
    "-- start_date (str, date, or datetime) [req]: the start date for which to grab USGS data\n",
    "-- end_date (str, date, or datetime) [req]: the end date for which to grab USGS data\n",
    "-- locations (dict) [req]: a dictionary (stationID/name:IDValue/latlong tuple) of locations to get USGS data for.\n",
    "-- return_type (string) [opt]: string indicating which format to return data in. Default is \"dict\", which will return data in a nested dict format:\n",
    "\t\t\t\t\t\t\t{locationID1:{\n",
    "\t\t\t\t\t\t\t\tvar1_name:pd.Series,\n",
    "\t\t\t\t\t\t\t\tvar2_name:pd.Series,\n",
    "\t\t\t\t\t\t\t\t...},\n",
    "\t\t\t\t\t\t\tlocationID2:{...},\n",
    "\t\t\t\t\t\t\t...\n",
    "\t\t\t\t\t\t\t}\n",
    "\t\t\t\t\t\t\tAlternative return type is \"dataframe\", which smashes all data into a single dataframe muliIndex'd by station ID, then timestamp\n",
    "\n",
    "Returns:\n",
    "USGS observed streamflow data for the given stations in the format specified by return_type\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0f5b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import data.usgs_ob as usgs\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d41c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USGS site numbers can be found at:\n",
    "# https://maps.waterdata.usgs.gov/mapper/index.html\n",
    "usgs_stations = {\"Missisquoi River\":\"04294000\",\n",
    "\t\t\t\t \"Jewett Brook\":\"04292810\",\n",
    "            \t \"Mill River\":\"04292750\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39fe331-60b4-468a-a29a-2c0cd11133a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "usgs_data = usgs.get_data(start_date = \"20240116\",\n",
    "\t\t\t\t\t\t  end_date = \"20240126\",\n",
    "\t\t\t\t\t\t  locations = usgs_stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c211c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(usgs_data['Missisquoi River']['streamflow'].astype('float') * 0.0283168)\n",
    "# pd.options.display.max_rows = 60\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1f624a-22dd-4b95-b1a3-4c3ca8868318",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(nwm_data['Missisquoi River']['streamflow'], label='NWM')\n",
    "# Convert from cubic ft/s (USGS) to cubic m/s (NWM)\n",
    "plt.plot(usgs_data['Missisquoi River']['streamflow'].astype('float') * 0.0283168, label='USGS')\n",
    "plt.xticks(rotation = 60)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fe6e55",
   "metadata": {},
   "source": [
    "## GFS forecasted meterological data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d1f56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Download specified GFS forecast data and return nested dictionary of pandas series fore each variable, for each location.\n",
    "\n",
    "Args:\n",
    "-- forecast_datetime (str, date, or datetime) [req]: the start date and time (00, 06, 12, 18) of the forecast to download. Times are assumed to be UTC time.\n",
    "-- end_datetime (str, date, or datetime) [req]: the end date and time for the forecast. GFS forecasts 16-days out for a given start date.\n",
    "-- locations (dict) [req]: a dictionary (stationID/name:IDValue/latlong tuple) of locations to download forecast data for.\n",
    "-- data_dir (str) [opt]: directory to store donwloaded data. Defaults to OS's default temp directory.\n",
    "-- dwnld_threads (int) [opt]: number of threads to use for downloads. Default is half of OS's available threads.\n",
    "-- load_threads (int) [opt]: number of threads to use for reading data. Default is 2 for GFS, since file reads are already pretty fast.\n",
    "-- return_type (string) [opt]: string indicating which format to return data in. Default is \"dict\", which will return data in a nested dict format:\n",
    "\t\t\t\t\t\t\t\t{locationID1:{\n",
    "\t\t\t\t\t\t\t\t\tvar1_name:pd.Series,\n",
    "\t\t\t\t\t\t\t\t\tvar2_name:pd.Series,\n",
    "\t\t\t\t\t\t\t\t\t...},\n",
    "\t\t\t\t\t\t\t\tlocationID2:{...},\n",
    "\t\t\t\t\t\t\t\t...\n",
    "\t\t\t\t\t\t\t\t}\n",
    "\t\t\t\t\t\t\t\tAlternative return type is \"dataframe\", which smashes all data into a single dataframe muliIndex'd by station ID, then timestamp\n",
    "\n",
    "Returns:\n",
    "GFS forecast data for the given locations in the format specified by return_type\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f5bea4-9c56-469e-89fa-e31a0260aa75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import data.gfs_fc as gfs\n",
    "\n",
    "start_dt = dt.datetime(2024, 1, 16)\n",
    "# wothout an hour specified, will default to midnight forecast cycle\n",
    "# fc_start_dt = \"202401016\"\n",
    "\n",
    "# use the same hour as our start datetime, so that we get a full 10 days of fc data\n",
    "end_dt = dt.datetime(2024, 1, 17)\n",
    "\n",
    "# define some locations to grab data for. Dictionary value must be lat/long tuple, up to 0.25 resolution\n",
    "stations = {'401': (45.00, -73.25),\n",
    "\t\t\t'402': (44.75, -73.25),\n",
    "\t\t\t'403': (44.75, -73.25)}\n",
    "\n",
    "# define a directory in which to download NWM data\n",
    "data_directory = \"/data/users/n/b/nbeckage/forecastData/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ea6f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gfs_data = gfs.get_data(forecast_datetime = start_dt,\n",
    "\t\t\t\t\t\tend_datetime = end_dt,\n",
    "\t\t\t\t\t\tlocations = stations,\n",
    "\t\t\t\t\t\tdata_dir = data_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8467c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check out the meterological variables downloaded - hardcoded for now\n",
    "gfs_data['401'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d53de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gfs_data['401']['T2']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a962e0-b715-48ee-96d2-c7938d71c463",
   "metadata": {},
   "source": [
    "## Observed local climatological data from NOAA\n",
    "[NCEI Data Service API User Documentation](https://www.ncei.noaa.gov/support/access-data-service-api-user-documentation)\n",
    "\n",
    "Additional LCD station IDs can be found at: https://www.ncei.noaa.gov/cdo-web/datatools/lcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f52afe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A function to download and process NOAA Local Climatological Data data to return nested dictionary of pandas series for each variable, for each location.\n",
    "\n",
    "Args:\n",
    "-- start_date (str, date, or datetime) [req]: the start date for which to grab LCD data\n",
    "-- end_date (str, date, or datetime) [req]: the end date for which to grab LCD data\n",
    "-- locations (dict) [req]: a dictionary (stationID/name:IDValue/latlong tuple) of locations to get USGS data for.\n",
    "-- return_type (string) [opt]: string indicating which format to return data in. Default is \"dict\", which will return data in a nested dict format:\n",
    "\t\t\t\t\t\t\t\t{locationID1:{\n",
    "\t\t\t\t\t\t\t\t\tvar1_name:pd.Series,\n",
    "\t\t\t\t\t\t\t\t\tvar2_name:pd.Series,\n",
    "\t\t\t\t\t\t\t\t\t...},\n",
    "\t\t\t\t\t\t\t\tlocationID2:{...},\n",
    "\t\t\t\t\t\t\t\t...\n",
    "\t\t\t\t\t\t\t\t}\n",
    "\t\t\t\t\t\t\t\tAlternative return type is \"dataframe\", which smashes all data into a single dataframe muliIndex'd by station ID, then timestamp\n",
    "\n",
    "Returns:\n",
    "NOAA Local Climatological Data (total cloud cover and precipitation currently) for the dat range and locations provided\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae1f125-a20f-42ce-8376-8e0247281b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import data.lcd_ob as lcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ac06ae-a2bd-4236-b0cd-3b22866b87dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lcd_data = lcd.get_data(start_date = start_dt,\n",
    "\t\t\t\t\t\tend_date = end_dt,\n",
    "\t\t\t\t\t\tlocations = {\"BTV\":\"72617014742\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34989a9-55de-4d44-badc-922bdea33252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local Climatological Dataset (LCD) only provides total cloud cover (%) and rain data\n",
    "lcd_data['BTV'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627081d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lcd_data['BTV']['TCDC']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d2ab6b",
   "metadata": {},
   "source": [
    "## Observed meterology data from UVM Forest Ecosystem Monitoring Cooperative (FEMC)\n",
    "Right now can be used to get Colchester reef quality-controlled met data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b5da97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A function to download and process observational meterological data from UVM FEMC (Forest Ecosysytem Monitoring Cooperative - https://www.uvm.edu/femc/) to return nested dictionary of pandas series for each variable, for each location.\n",
    "\n",
    "Args:\n",
    "-- start_date (str, date, or datetime) [req]: the start date for which to grab FEMC data\n",
    "-- end_date (str, date, or datetime) [req]: the end date for which to grab FEMC data\n",
    "-- locations (dict) [req]: a dictionary (stationID/name:IDValue/latlong tuple) of locations to get FEMC data for.\n",
    "-- return_type (string) [opt]: string indicating which format to return data in. Default is \"dict\", which will return data in a nested dict format:\n",
    "\t\t\t\t\t\t\t\t{locationID1:{\n",
    "\t\t\t\t\t\t\t\t\tvar1_name:pd.Series,\n",
    "\t\t\t\t\t\t\t\t\tvar2_name:pd.Series,\n",
    "\t\t\t\t\t\t\t\t\t...},\n",
    "\t\t\t\t\t\t\t\tlocationID2:{...},\n",
    "\t\t\t\t\t\t\t\t...\n",
    "\t\t\t\t\t\t\t\t}\n",
    "\t\t\t\t\t\t\t\tAlternative return type is \"dataframe\", which smashes all data into a single dataframe muliIndex'd by station ID, then timestamp\n",
    "\n",
    "Returns:\n",
    "FEMC obsrvational meterological data for the specifed data range and locations, in the format specified by return_type\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3bedef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import data.femc_ob as femc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8991f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "femc_data = femc.get_data(start_date = start_dt,\n",
    "\t\t\t\t\t\t  end_date = end_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6e82f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking a look at what meterological vars we have\n",
    "femc_data['CR'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163cb3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "femc_data['CR']['T2']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
